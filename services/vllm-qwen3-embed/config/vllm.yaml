# vLLM OpenAI-compatible embedding service config
model: /models/Qwen3-Embedding-8B
served_model_name: qwen3-embed-8b

host: 0.0.0.0
port: 8000

# Use a real secret manager in prod; for local dev it's fine
api_key: eslllm

# Perf / memory knobs (optional)
dtype: auto


max_model_len: 512
max_num_seqs: 8
max_num_batched_tokens: 2048
gpu_memory_utilization: 0.80
dtype: auto